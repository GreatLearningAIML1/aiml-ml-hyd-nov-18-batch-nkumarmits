{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "R7_InternalLab_Questions_Hyd_Nov18.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MyfMmMnPJjvn"
      },
      "source": [
        "## Train a simple convnet on the Fashion MNIST dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zjcGOJhcJjvp"
      },
      "source": [
        "In this, we will see how to deal with image data and train a convnet for image classification task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jR0Pl2XjJjvq"
      },
      "source": [
        "### Load the  `fashion_mnist`  dataset\n",
        "\n",
        "** Use keras.datasets to load the dataset **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Qr75v_UYJjvs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "f0b0b6b1-4953-4d41-8c6f-85c4ad20b79c"
      },
      "source": [
        "import keras\n",
        "import tensorflow as tf\n",
        "from keras.layers import Dense,Flatten,Activation,Dropout,BatchNormalization, Conv2D,MaxPool2D\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "\n",
        "#from keras.datasets import fashion_mnist\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hTI42-0qJjvw"
      },
      "source": [
        "### Find no.of samples are there in training and test datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "g2sf67VoJjvx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "0c99fd99-55e1-44e9-9492-925e57227bb8"
      },
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "(60000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zewyDcBlJjv1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "3a9d8e1f-f7f3-418f-b7d4-df87fd94dc04"
      },
      "source": [
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 28, 28)\n",
            "(10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WytT2eRnJjv4"
      },
      "source": [
        "### Find dimensions of an image in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XycQGBSGJjv5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7c951c83-20b7-4da2-fa7b-33b6937ade68"
      },
      "source": [
        "x_train[0].shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5jtdZ7RqJjv8"
      },
      "source": [
        "### Convert train and test labels to one hot vectors\n",
        "\n",
        "** check `keras.utils.to_categorical()` **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sAD3q5I6Jjv9",
        "colab": {}
      },
      "source": [
        "y_train = keras.utils.to_categorical(y_train,num_classes=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mgHSCXy3JjwA",
        "colab": {}
      },
      "source": [
        "y_test = keras.utils.to_categorical(y_test,num_classes=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xO5BRBzBJjwD"
      },
      "source": [
        "### Normalize both the train and test image data from 0-255 to 0-1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3fUQpMHxJjwE",
        "colab": {}
      },
      "source": [
        "#Build graph\n",
        "model = keras.models.Sequential()\n",
        "x_train = x_train/255\n",
        "y_train = y_train/255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Okwo_SB5JjwI",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "da5-DwgrJjwM"
      },
      "source": [
        "### Reshape the data from 28x28 to 28x28x1 to match input dimensions in Conv2D layer in keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LPGVQ-JJJjwN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0f55efbb-e8dc-4ac3-a09f-506f27707912"
      },
      "source": [
        "x_train = x_train.reshape((-1,28,28,1))\n",
        "x_test = x_test.reshape((-1,28,28,1))\n",
        "x_train.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OFRRTJq8JjwQ"
      },
      "source": [
        "### Import the necessary layers from keras to build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dWTZYnKSJjwR",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "import tensorflow as tf\n",
        "from keras.layers import Dense,Flatten,Activation,Dropout,BatchNormalization, Conv2D,MaxPool2D\n",
        "from keras.callbacks import EarlyStopping"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "C18AoS7eJjwU"
      },
      "source": [
        "### Build a model \n",
        "\n",
        "** with 2 Conv layers having `32 3*3 filters` in both convolutions with `relu activations` and `flatten` before passing the feature map into 2 fully connected layers (or Dense Layers) having 128 and 10 neurons with `relu` and `softmax` activations respectively. Now, using `categorical_crossentropy` loss with `adam` optimizer train the model with early stopping `patience=5` and no.of `epochs=10`. **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DORCLgSwJjwV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "822f8630-1dc4-4aa1-cfb8-df11a748d593"
      },
      "source": [
        "#Applying Conv Layers, MaxPooling\n",
        "model.add(keras.layers.Conv2D(32,(3,3),activation='relu'))\n",
        "model.add(keras.layers.Conv2D(32,(3,3),activation='relu'))\n",
        "\n",
        "# Flatten\n",
        "model.add(keras.layers.Flatten())\n",
        "\n",
        "# passing feature map into 2 fully connected layers\n",
        "\n",
        "model.add(keras.layers.Dense(128,activation='relu'))\n",
        "model.add(keras.layers.Dense(10,activation='softmax'))\n",
        "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxkQ-0mDefNN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "outputId": "55d08610-4521-48f7-d5e1-09719d2cbd10"
      },
      "source": [
        "%%time\n",
        "#callbacks = [EarlyStopping(monitor='val_loss', patience=5, mode='auto')]\n",
        "model.fit(x_train,y_train, \n",
        "          validation_data=(x_test,y_test),\n",
        "          epochs=10,batch_size=32,\n",
        "          callbacks=[EarlyStopping(monitor='val_loss', \n",
        "          patience=5, mode='auto')]\n",
        "         )"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 25s 425us/step - loss: 0.0015 - acc: 0.8650 - val_loss: 1.8379 - val_acc: 0.8826\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 19s 318us/step - loss: 8.9923e-04 - acc: 0.9153 - val_loss: 1.6979 - val_acc: 0.8923\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 19s 319us/step - loss: 6.5270e-04 - acc: 0.9386 - val_loss: 1.7757 - val_acc: 0.8876\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 19s 318us/step - loss: 4.5658e-04 - acc: 0.9562 - val_loss: 1.8051 - val_acc: 0.8855\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 19s 318us/step - loss: 3.1450e-04 - acc: 0.9702 - val_loss: 2.1122 - val_acc: 0.8667\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 19s 319us/step - loss: 2.1162e-04 - acc: 0.9806 - val_loss: 1.9614 - val_acc: 0.8774\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 19s 323us/step - loss: 1.5082e-04 - acc: 0.9864 - val_loss: 2.2917 - val_acc: 0.8568\n",
            "CPU times: user 2min 10s, sys: 30.6 s, total: 2min 40s\n",
            "Wall time: 2min 21s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0c8627aa90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ju69vKdIJjwX"
      },
      "source": [
        "### Now, to the above model add `max` pooling layer of `filter size 2x2` and `dropout` layer with `p=0.25` after the 2 conv layers and run the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "L2hAP94vJjwY",
        "colab": {}
      },
      "source": [
        "modelA = keras.models.Sequential()\n",
        "modelA.add(keras.layers.BatchNormalization())\n",
        "\n",
        "\n",
        "modelA.add(keras.layers.Conv2D(32,(3,3),activation='relu'))\n",
        "modelA.add(keras.layers.Conv2D(32,(3,3),activation='relu'))\n",
        "\n",
        "modelA.add(keras.layers.MaxPool2D(pool_size=(2,2)))\n",
        "modelA.add(keras.layers.Dropout(.25))\n",
        "\n",
        "modelA.add(keras.layers.Flatten())\n",
        "\n",
        "modelA.add(keras.layers.Dense(128,activation='relu'))\n",
        "modelA.add(keras.layers.Dense(10,activation='softmax'))\n",
        "modelA.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lGTA3bfEJjwa"
      },
      "source": [
        "### Now, to the above model, lets add Data Augmentation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BC85BPmHg0dx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform_fn = keras.preprocessing.image.ImageDataGenerator(horizontal_flip=True,width_shift_range=0.2,height_shift_range=0.2,rotation_range=30,             \n",
        "                                                               shear_range=0.2,\n",
        "                                                               zoom_range=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "F6gX8n5SJjwb"
      },
      "source": [
        "### Import the ImageDataGenrator from keras and fit the training images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Cbz4uHBuJjwc",
        "colab": {}
      },
      "source": [
        "transform_fn.fit(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pl-8dOo7Jjwf"
      },
      "source": [
        "#### Showing 5 versions of the first image in training dataset using image datagenerator.flow()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DpI1_McYJjwg",
        "outputId": "4c82b4c7-d0d6-4f2f-fe8a-f9ed6694c716",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "gen = transform_fn.flow(x_train[0:1], batch_size=1)\n",
        "for i in range(1, 6):\n",
        "    plt.subplot(1,5,i)\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(gen.next().squeeze(), cmap='gray')\n",
        "    plt.plot()\n",
        "plt.show()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAABcCAYAAABz9T77AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncP4Pg3jJfOLTs9gAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dmPl5yE8Jjwm"
      },
      "source": [
        "### Run the above model using fit_generator()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "44ZnDdJYJjwn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "outputId": "7cd248d3-c095-4646-cad1-74f7f1ddfcc0"
      },
      "source": [
        "%%time\n",
        "modelA.fit_generator(transform_fn.flow(x_train,y_train,batch_size=32),\n",
        "                     steps_per_epoch=len(x_train)/32,\n",
        "                     epochs=10,\n",
        "                     callbacks=[EarlyStopping(monitor='loss', patience=5, mode='auto')]\n",
        "                    )"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 35s 19ms/step - loss: 0.0034 - acc: 0.6770\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 35s 19ms/step - loss: 0.0026 - acc: 0.7544\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 35s 19ms/step - loss: 0.0024 - acc: 0.7725\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 36s 19ms/step - loss: 0.0023 - acc: 0.7878\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 36s 19ms/step - loss: 0.0022 - acc: 0.7953\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 36s 19ms/step - loss: 0.0021 - acc: 0.8044\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 35s 19ms/step - loss: 0.0020 - acc: 0.8072\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 35s 19ms/step - loss: 0.0020 - acc: 0.8137\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 35s 19ms/step - loss: 0.0020 - acc: 0.8163\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 35s 19ms/step - loss: 0.0019 - acc: 0.8175\n",
            "CPU times: user 8min 32s, sys: 33.3 s, total: 9min 5s\n",
            "Wall time: 5min 52s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0c6d689630>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MwQQW5iOJjwq"
      },
      "source": [
        "###  Report the final train and validation accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "c1SrtBEPJjwq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "e1c66d81-d9d0-4cf6-d8c6-d79b90f7bcb6"
      },
      "source": [
        "modelA.evaluate(x_train,y_train)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 6s 94us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0013652267111620554, 0.87295]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZBwVWNQC2qZD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "734aba07-d3c3-4119-f97d-6f7aa510a93f"
      },
      "source": [
        "modelA.evaluate(x_test,y_test)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 90us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[7.677103821563721, 0.5167]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LazEiu-jAOB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "bba92a86-da25-450a-b6c7-b059d596de1a"
      },
      "source": [
        "print('The train accuracy is',modelA.evaluate(x_train,y_train)[1])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 6s 95us/step\n",
            "The train accuracy is 0.87295\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8EGqDb4jHSP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "8e9a0e2d-32d5-4b30-87f2-d7ca5822c6fc"
      },
      "source": [
        "print('The test accuracy is',modelA.evaluate(x_test,y_test)[1])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 95us/step\n",
            "The test accuracy is 0.5167\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eM6hfQRqjYAT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}